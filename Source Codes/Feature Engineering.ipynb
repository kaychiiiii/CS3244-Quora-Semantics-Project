{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Feature Engineering.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1opclJNtzOZS"},"source":["# Colab for Feature Engineering.  #\n","\n","---\n","\n","\n","## To Do: ##\n","1. Separate the Duplicates and Non-Duplicates\n","2. Copy the DataFrames into new variables\n","3. Process the data into the feature to be extracted\n","4. Plot the Histogram to see to observe the distribution\n","\n","\n","---\n","\n","\n","##Features##\n","\n","1. Number of unique words which occur in q1 and q2 \n","2. Ratio of common words / total words (q1+q2)\n","2. Common Word Ratio min ( words common/ min(len(q1), len(q2)))\n","2. Common Word Ratio mmax ( words common/ max(len(q1), len(q2)))\n","2. Common Stop Words min ( common stopwords/ min(len(q1), len(q2)))\n","2. Common Stop Words max  ( common stopwords/ max(len(q1), len(q2)))\n","2. Common Tokens min ( common Tokens / min(len(q1), len(q2)))\n","2. Common Tokens max  ( common Tokens / max(len(q1), len(q2)))\n","2. Common Adjectives min ( common adjectives /min(len(q1), len(q2)))\n","2. Common Adjectives max ( common adjectives /max(len(q1), len(q2)))\n","2. Common Noun min ( common nouns / min(len(q1), len(q2)))\n","2. Common Noun max ( common nouns / max(len(q1), len(q2)))\n","2. Fuzz ratio\n","2. Fuzz partial ratio \n","2. Fuzz Token Sort Ratio \n","2. Fuzz Token Set Ratio\n","2. Mean Length of 2 questions\n","2. Ratio of Length of Questions ( len(q1) / len(q2) )\n","2. Absolute Length Difference (| len(q1) - len(q2) |\n","2. Longest Matching Substring min ( longest substring/min(len(q1), len(q2)))\n","2. Longest Matching Substring max ( longest substring/max(len(q1), len(q2)))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aitd3DXdGW02"},"source":["Download your required libraries here"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cp6xm-95GQR6","executionInfo":{"status":"ok","timestamp":1632906773421,"user_tz":-480,"elapsed":120505,"user":{"displayName":"Penn Han Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06071372039627482089"}},"outputId":"637077ec-d3d9-47af-beeb-683b98739ea3"},"source":["!pip install bs4\n","!pip install fuzzywuzzy\n","!pip install TextBlob\n","!python -m spacy download en_core_web_lg"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: bs4 in c:\\python38\\lib\\site-packages (0.0.1)\n","Requirement already satisfied: beautifulsoup4 in c:\\python38\\lib\\site-packages (from bs4) (4.9.3)\n","Requirement already satisfied: soupsieve>1.2 in c:\\python38\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n","You should consider upgrading via the 'c:\\python38\\python.exe -m pip install --upgrade pip' command.\n"]},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: fuzzywuzzy in c:\\python38\\lib\\site-packages (0.18.0)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n","You should consider upgrading via the 'c:\\python38\\python.exe -m pip install --upgrade pip' command.\n"]},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: TextBlob in c:\\python38\\lib\\site-packages (0.15.3)\n","Requirement already satisfied: nltk>=3.1 in c:\\python38\\lib\\site-packages (from TextBlob) (3.6.3)\n","Requirement already satisfied: click in c:\\python38\\lib\\site-packages (from nltk>=3.1->TextBlob) (7.1.2)\n","Requirement already satisfied: regex in c:\\python38\\lib\\site-packages (from nltk>=3.1->TextBlob) (2021.4.4)\n","Requirement already satisfied: tqdm in c:\\python38\\lib\\site-packages (from nltk>=3.1->TextBlob) (4.61.0)\n","Requirement already satisfied: joblib in c:\\python38\\lib\\site-packages (from nltk>=3.1->TextBlob) (1.0.1)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n","You should consider upgrading via the 'c:\\python38\\python.exe -m pip install --upgrade pip' command.\n","WARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n","You should consider upgrading via the 'C:\\Python38\\python.exe -m pip install --upgrade pip' command.\n"]},{"output_type":"stream","name":"stdout","text":["Collecting en-core-web-lg==3.1.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.1.0/en_core_web_lg-3.1.0-py3-none-any.whl (777.1 MB)\n","Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\python38\\lib\\site-packages (from en-core-web-lg==3.1.0) (3.1.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (4.61.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.25.1)\n","Requirement already satisfied: setuptools in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (41.2.0)\n","Requirement already satisfied: packaging>=20.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (20.9)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.0.5)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.7.4)\n","Requirement already satisfied: numpy>=1.15.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.20.3)\n","Requirement already satisfied: jinja2 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.5)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.4.1)\n","Requirement already satisfied: pathy>=0.3.5 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.5.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.7.4)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.8.2)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.9 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (8.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.5)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.3.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in c:\\python38\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.4.7)\n","Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\python38\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.26.4)\n","Requirement already satisfied: chardet<5,>=3.0.2 in c:\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in c:\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2020.12.5)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\python38\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\python38\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.1)\n","[+] Download and installation successful\n","You can now load the package via spacy.load('en_core_web_lg')\n","Collecting en-core-web-lg==3.1.0"]},{"output_type":"stream","name":"stderr","text":["WARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n","You should consider upgrading via the 'C:\\Python38\\python.exe -m pip install --upgrade pip' command.\n"]},{"output_type":"stream","name":"stdout","text":["\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.1.0/en_core_web_lg-3.1.0-py3-none-any.whl (777.1 MB)\n","Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\python38\\lib\\site-packages (from en-core-web-lg==3.1.0) (3.1.3)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.6)\n","Requirement already satisfied: pathy>=0.3.5 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.5.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (4.61.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.8.2)\n","Requirement already satisfied: numpy>=1.15.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.20.3)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.3.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.7.4)\n","Requirement already satisfied: packaging>=20.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (20.9)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.7.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.25.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.0.5)\n","Requirement already satisfied: jinja2 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.1)\n","Requirement already satisfied: setuptools in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (41.2.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.4.1)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.9 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (8.0.10)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.8)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\python38\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in c:\\python38\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.4.7)\n","Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in c:\\python38\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.26.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2020.12.5)\n","Requirement already satisfied: chardet<5,>=3.0.2 in c:\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in c:\\python38\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.10)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in c:\\python38\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\python38\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.1)\n","[+] Download and installation successful\n","You can now load the package via spacy.load('en_core_web_lg')\n"]}]},{"cell_type":"markdown","metadata":{"id":"urv0kxsD0z-P"},"source":["Import your required libraries here"]},{"cell_type":"code","metadata":{"id":"2GtU4YrQ0zuM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632906776310,"user_tz":-480,"elapsed":2886,"user":{"displayName":"Penn Han Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06071372039627482089"}},"outputId":"35c678eb-0ade-4980-c65a-8ace373dd054"},"source":["import pandas as pd\n","import numpy as np\n","import re\n","from bs4 import BeautifulSoup\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","import nltk\n","from fuzzywuzzy import fuzz\n","from difflib import SequenceMatcher #For finding longest substring\n","from textblob import TextBlob\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import spacy\n","import en_core_web_lg\n","nlp = spacy.load('en_core_web_lg')\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger') # for pos tagging\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\luciu\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\luciu\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\luciu\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":77}]},{"cell_type":"markdown","metadata":{"id":"0-b9QIRu0bLP"},"source":["Mounting the dataset onto this google colab"]},{"cell_type":"code","metadata":{"id":"DWi8Re2HzG5o"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/MyDrive/CS3244 45 Project/quora-question-pairs/\"\n","train_set = pd.read_csv('./train.csv')\n","test_set = pd.read_csv('./test.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7nDsIvWq3G_C"},"source":["%cd './Desktop/CS3244/Project/quora-question-pairs'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qusSW7kt0uRc"},"source":["# train_set = pd.read_csv('train.csv')\n","\n","train_set = pd.read_csv('./Desktop/NUS Lecture Notes/Y3S1/CS3244/Project/train.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mobCdQl5MTkq"},"source":["##**Dropping NA Rows**"]},{"cell_type":"code","metadata":{"id":"U2Rw0SY5Pyvx"},"source":["train_set.dropna(inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JiqKVmcHMYtJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632906778500,"user_tz":-480,"elapsed":152,"user":{"displayName":"Penn Han Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06071372039627482089"}},"outputId":"7c6d81f8-a547-473e-9a77-6afc711bd441"},"source":["train_set.info()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 404287 entries, 0 to 404289\n","Data columns (total 6 columns):\n"," #   Column        Non-Null Count   Dtype \n","---  ------        --------------   ----- \n"," 0   id            404287 non-null  int64 \n"," 1   qid1          404287 non-null  int64 \n"," 2   qid2          404287 non-null  int64 \n"," 3   question1     404287 non-null  object\n"," 4   question2     404287 non-null  object\n"," 5   is_duplicate  404287 non-null  int64 \n","dtypes: int64(4), object(2)\n","memory usage: 21.6+ MB\n"]}]},{"cell_type":"markdown","metadata":{"id":"Tgik8RWhM61f"},"source":["##**Preprocess the questions**"]},{"cell_type":"code","metadata":{"id":"01o0b7ktMaUt"},"source":["# This function accepts a question and preprocesses it. Returns cleaned question.\n","def preprocess(q):\n","  # Firstly, we convert to lowercase and remove trailing and leading spaces\n","  q = str(q).lower().strip()\n","\n","  # Replace certain special characters with their string equivalents\n","  q = q.replace('%', ' percent')\n","  q = q.replace('$', ' dollar ')\n","  q = q.replace('₹', ' rupee ')\n","  q = q.replace('€', ' euro ')\n","  q = q.replace('@', ' at ')\n","\n","  # The pattern '[math]' appears around 900 times in the whole dataset.\n","  q = q.replace('[math]', '')\n","\n","  # Replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)\n","  q = q.replace(',000,000,000 ', 'b ')\n","  q = q.replace(',000,000 ', 'm ')\n","  q = q.replace(',000 ', 'k ')\n","  q = re.sub(r'([0-9]+)000000000', r'\\1b', q)\n","  q = re.sub(r'([0-9]+)000000', r'\\1m', q)\n","  q = re.sub(r'([0-9]+)000', r'\\1k', q)\n","\n","  # Decontracting words\n","  # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n","  # https://stackoverflow.com/a/19794953\n","  contractions = { \n","    \"ain't\": \"am not\",\n","    \"aren't\": \"are not\",\n","    \"can't\": \"can not\",\n","    \"can't've\": \"can not have\",\n","    \"'cause\": \"because\",\n","    \"could've\": \"could have\",\n","    \"couldn't\": \"could not\",\n","    \"couldn't've\": \"could not have\",\n","    \"didn't\": \"did not\",\n","    \"doesn't\": \"does not\",\n","    \"don't\": \"do not\",\n","    \"hadn't\": \"had not\",\n","    \"hadn't've\": \"had not have\",\n","    \"hasn't\": \"has not\",\n","    \"haven't\": \"have not\",\n","    \"he'd\": \"he would\",\n","    \"he'd've\": \"he would have\",\n","    \"he'll\": \"he will\",\n","    \"he'll've\": \"he will have\",\n","    \"he's\": \"he is\",\n","    \"how'd\": \"how did\",\n","    \"how'd'y\": \"how do you\",\n","    \"how'll\": \"how will\",\n","    \"how's\": \"how is\",\n","    \"i'd\": \"i would\",\n","    \"i'd've\": \"i would have\",\n","    \"i'll\": \"i will\",\n","    \"i'll've\": \"i will have\",\n","    \"i'm\": \"i am\",\n","    \"i've\": \"i have\",\n","    \"isn't\": \"is not\",\n","    \"it'd\": \"it would\",\n","    \"it'd've\": \"it would have\",\n","    \"it'll\": \"it will\",\n","    \"it'll've\": \"it will have\",\n","    \"it's\": \"it is\",\n","    \"let's\": \"let us\",\n","    \"ma'am\": \"madam\",\n","    \"mayn't\": \"may not\",\n","    \"might've\": \"might have\",\n","    \"mightn't\": \"might not\",\n","    \"mightn't've\": \"might not have\",\n","    \"must've\": \"must have\",\n","    \"mustn't\": \"must not\",\n","    \"mustn't've\": \"must not have\",\n","    \"needn't\": \"need not\",\n","    \"needn't've\": \"need not have\",\n","    \"o'clock\": \"of the clock\",\n","    \"oughtn't\": \"ought not\",\n","    \"oughtn't've\": \"ought not have\",\n","    \"shan't\": \"shall not\",\n","    \"sha'n't\": \"shall not\",\n","    \"shan't've\": \"shall not have\",\n","    \"she'd\": \"she would\",\n","    \"she'd've\": \"she would have\",\n","    \"she'll\": \"she will\",\n","    \"she'll've\": \"she will have\",\n","    \"she's\": \"she is\",\n","    \"should've\": \"should have\",\n","    \"shouldn't\": \"should not\",\n","    \"shouldn't've\": \"should not have\",\n","    \"so've\": \"so have\",\n","    \"so's\": \"so as\",\n","    \"that'd\": \"that would\",\n","    \"that'd've\": \"that would have\",\n","    \"that's\": \"that is\",\n","    \"there'd\": \"there would\",\n","    \"there'd've\": \"there would have\",\n","    \"there's\": \"there is\",\n","    \"they'd\": \"they would\",\n","    \"they'd've\": \"they would have\",\n","    \"they'll\": \"they will\",\n","    \"they'll've\": \"they will have\",\n","    \"they're\": \"they are\",\n","    \"they've\": \"they have\",\n","    \"to've\": \"to have\",\n","    \"wasn't\": \"was not\",\n","    \"we'd\": \"we would\",\n","    \"we'd've\": \"we would have\",\n","    \"we'll\": \"we will\",\n","    \"we'll've\": \"we will have\",\n","    \"we're\": \"we are\",\n","    \"we've\": \"we have\",\n","    \"weren't\": \"were not\",\n","    \"what'll\": \"what will\",\n","    \"what'll've\": \"what will have\",\n","    \"what're\": \"what are\",\n","    \"what's\": \"what is\",\n","    \"what've\": \"what have\",\n","    \"when's\": \"when is\",\n","    \"when've\": \"when have\",\n","    \"where'd\": \"where did\",\n","    \"where's\": \"where is\",\n","    \"where've\": \"where have\",\n","    \"who'll\": \"who will\",\n","    \"who'll've\": \"who will have\",\n","    \"who's\": \"who is\",\n","    \"who've\": \"who have\",\n","    \"why's\": \"why is\",\n","    \"why've\": \"why have\",\n","    \"will've\": \"will have\",\n","    \"won't\": \"will not\",\n","    \"won't've\": \"will not have\",\n","    \"would've\": \"would have\",\n","    \"wouldn't\": \"would not\",\n","    \"wouldn't've\": \"would not have\",\n","    \"y'all\": \"you all\",\n","    \"y'all'd\": \"you all would\",\n","    \"y'all'd've\": \"you all would have\",\n","    \"y'all're\": \"you all are\",\n","    \"y'all've\": \"you all have\",\n","    \"you'd\": \"you would\",\n","    \"you'd've\": \"you would have\",\n","    \"you'll\": \"you will\",\n","    \"you'll've\": \"you will have\",\n","    \"you're\": \"you are\",\n","    \"you've\": \"you have\"\n","  }\n","\n","  q_decontracted = []\n","\n","  for word in q.split():\n","    if word in contractions:\n","      word = contractions[word]\n","  \n","    q_decontracted.append(word)\n","\n","  q = ' '.join(q_decontracted)\n","  q = q.replace(\"'ve\", \" have\")\n","  q = q.replace(\"n't\", \" not\")\n","  q = q.replace(\"'re\", \" are\")\n","  q = q.replace(\"'ll\", \" will\")\n","\n","  # Removing HTML tags\n","  q = BeautifulSoup(q)\n","  q = q.get_text()\n","\n","  # Remove punctuations\n","  pattern = re.compile('\\W')\n","  q = re.sub(pattern, ' ', q).strip()\n","\n","  return q"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RMpr__5tND0V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632907149161,"user_tz":-480,"elapsed":370604,"user":{"displayName":"Penn Han Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06071372039627482089"}},"outputId":"852605f8-5755-40f2-a127-e5fe0f9606d5"},"source":["train_set['question1'] = train_set['question1'].apply(preprocess)\n","train_set['question2'] = train_set['question2'].apply(preprocess)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["c:\\python38\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZHo_Olr-SpfX"},"source":["##**Removing empty questions**"]},{"cell_type":"code","metadata":{"id":"RMzSgzS-SDCJ"},"source":["train_set = train_set.drop(train_set[train_set['question1'] == ''].index)\n","train_set = train_set.drop(train_set[train_set['question2'] == ''].index)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"chHSSf-lOAK9"},"source":["##**Jun An**\n","\n","1. Ratio of Common Words (Common words / total words) (Done)\n","2. Ratio of Common Tokens (Common tokens/ max(q1, q2)) (Done)\n","3. Fuzz partial ratio (Done)\n","4. Longest Matching Substring Min (Done)"]},{"cell_type":"code","metadata":{"id":"4kNBhBLUNUjz"},"source":["def num_common_words_ratio(row):\n","  set1 = set(row['question1'].lower().split())\n","  set2 = set(row['question2'].lower().split())\n","  total = len(set1) + len(set2)\n","  return len(set1.intersection(set2))/total"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YBON_ODoPR4z"},"source":["train_set['common_words_ratio'] = train_set.apply(num_common_words_ratio, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38QSMNbEQVhh"},"source":["def common_tokens_ratio_max(row):\n","  q1 = set(word_tokenize(row['question1'].lower()))\n","  q2 = set(word_tokenize(row['question2'].lower()))\n","  stop_words = set(stopwords.words('english'))\n","  token1 = [word for word in q1 if word not in stop_words]\n","  token2 = [word for word in q2 if word not in stop_words]\n","  ratio = len(set(token1).intersection(set(token2))) / max(len(row['question1']), len(row['question2']))\n","\n","  return ratio\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xh1JHVdwUBvv"},"source":["train_set['common_tokens_ratio'] = train_set.apply(common_tokens_ratio_max, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZuilUh04Urcu"},"source":["def fuzz_partial_ratio(row):\n","  q1 = row['question1']\n","  q2 = row['question2']\n","  fuzz_partial = fuzz.partial_ratio(q1,q2)\n","  return fuzz_partial"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLiC1eTeefb1"},"source":["train_set['fuzz_partial_ratio'] = train_set.apply(fuzz_partial_ratio, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7Z_z7fHelbz"},"source":["def min_longest_substring(row):\n","  q1 = row['question1']\n","  q2 = row['question2']\n","  match = SequenceMatcher(None, q1, q2).find_longest_match(0, len(q1), 0, len(q2))\n","  return match.size/min(len(q1), len(q2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EBizZQ4BiNp8"},"source":["train_set['min_longest_substring'] = train_set.apply(min_longest_substring, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJiuPhLZpEVL","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1632907940831,"user_tz":-480,"elapsed":121,"user":{"displayName":"Penn Han Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06071372039627482089"}},"outputId":"b04ccc1d-5e6f-453f-f5c0-31c132b05f50"},"source":["train_set.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id  qid1  qid2                                          question1  \\\n","0   0     1     2  what is the step by step guide to invest in sh...   \n","1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n","2   2     5     6  how can i increase the speed of my internet co...   \n","3   3     7     8  why am i mentally very lonely  how can i solve it   \n","4   4     9    10  which one dissolve in water quikly sugar  salt...   \n","\n","                                           question2  is_duplicate  \\\n","0  what is the step by step guide to invest in sh...             0   \n","1  what would happen if the indian government sto...             0   \n","2  how can internet speed be increased by hacking...             0   \n","3  find the remainder when 23  24   math  is divi...             0   \n","4             which fish would survive in salt water             0   \n","\n","   common_words_ratio  common_tokens_ratio  fuzz_partial_ratio  \\\n","0            0.478261             0.076923                 100   \n","1            0.291667             0.045977                  74   \n","2            0.166667             0.027778                  46   \n","3            0.000000             0.000000                  11   \n","4            0.200000             0.026667                  55   \n","\n","   min_longest_substring  \n","0               1.000000  \n","1               0.600000  \n","2               0.172414  \n","3               0.040816  \n","4               0.157895  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","      <th>common_words_ratio</th>\n","      <th>common_tokens_ratio</th>\n","      <th>fuzz_partial_ratio</th>\n","      <th>min_longest_substring</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","      <td>0.478261</td>\n","      <td>0.076923</td>\n","      <td>100</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>what is the story of kohinoor  koh i noor  dia...</td>\n","      <td>what would happen if the indian government sto...</td>\n","      <td>0</td>\n","      <td>0.291667</td>\n","      <td>0.045977</td>\n","      <td>74</td>\n","      <td>0.600000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>how can i increase the speed of my internet co...</td>\n","      <td>how can internet speed be increased by hacking...</td>\n","      <td>0</td>\n","      <td>0.166667</td>\n","      <td>0.027778</td>\n","      <td>46</td>\n","      <td>0.172414</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>why am i mentally very lonely  how can i solve it</td>\n","      <td>find the remainder when 23  24   math  is divi...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11</td>\n","      <td>0.040816</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>which one dissolve in water quikly sugar  salt...</td>\n","      <td>which fish would survive in salt water</td>\n","      <td>0</td>\n","      <td>0.200000</td>\n","      <td>0.026667</td>\n","      <td>55</td>\n","      <td>0.157895</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":92}]},{"cell_type":"markdown","metadata":{"id":"7E95ziqm9V2X"},"source":["##**Penn Han**\n","\n","1. Number of unique words that occur in q1 and q2\n","2. Ratio of Common Tokens to min(len(q1), len(q2))\n","3. Fuzz Ratio\n","4. Absolute Length Difference between q1 and q2\n","5. Mean TF-IDF value\n","6. Mean IDF-weighted vector"]},{"cell_type":"code","metadata":{"id":"l2MxJruy92k6"},"source":["def unique_words_count(row):\n","  set1 = set(row['question1'].lower().split())\n","  set2 = set(row['question2'].lower().split())\n","  return len(set1.intersection(set2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lPu-PNRp-SEw"},"source":["train_set[\"unique_words_count\"] = train_set.apply(unique_words_count, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7CGxW3M99dO"},"source":["def common_token_ratio_min(row):\n","  q1 = set(word_tokenize(row['question1'].lower()))\n","  q2 = set(word_tokenize(row['question2'].lower()))\n","  stop_words = set(stopwords.words('english'))\n","  token1 = [word for word in q1 if word not in stop_words]\n","  token2 = [word for word in q2 if word not in stop_words]\n","  ratio = len(set(token1).intersection(set(token2))) / min(len(row['question1']), len(row['question2']))\n","  return ratio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nc5nl8WB-SkC"},"source":["train_set[\"common_token_ratio_min\"] = train_set.apply(common_token_ratio_min, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3tve1rwe-J91"},"source":["def fuzz_ratio(row):\n","  q1 = row['question1']\n","  q2 = row['question2']\n","  fuzz_ratio = fuzz.ratio(q1,q2)\n","  return fuzz_ratio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWS9n2_F-TPt"},"source":["train_set[\"fuzz_ratio\"] = train_set.apply(fuzz_ratio, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ns-DI5-q-NDP"},"source":["def abs_len_difference(row):\n","  q1 = row['question1']\n","  q2 = row['question2']\n","  abs_len_diff = abs(len(q1) - len(q2))\n","  return abs_len_diff"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3a2P53aI-TtU"},"source":["train_set[\"abs_len_difference\"] = train_set.apply(abs_len_difference, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H7_C-NlBvGHx"},"source":["#Stop words not removed PLEASE ONLY USE EITHER THIS OR THE BELOW, NOT BOTH\n","\n","tf_idf_vectoriser = TfidfVectorizer(lowercase=True)\n","q1_train_list = list(train_set['question1'])\n","q2_train_list = list(train_set['question2'])\n","question_corpus = list(q1_train_list + q2_train_list)\n","tf_idf_vectoriser.fit(question_corpus)\n","idf = dict(zip(tf_idf_vectoriser.get_feature_names(), tf_idf_vectoriser.idf_))  #For Weighted W2V\n","nlp = en_core_web_lg.load()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UeSYC_KOi5Q7"},"source":["#Stop words removed  PLEASE ONLY USE THIS OR THE ABOVE, NOT BOTH\n","\n","tf_idf_vectoriser = TfidfVectorizer(lowercase=True)\n","stop_words = set(stopwords.words('english'))\n","question_corpus = []\n","for question1, question2 in zip(list(train_set['question1']), list(train_set['question2'])):\n","  q1 = word_tokenize(question1.lower())  \n","  token1 = \" \".join([word for word in q1 if word not in stop_words])\n","  q2 = word_tokenize(question2.lower())\n","  token2 = \" \".join([word for word in q2 if word not in stop_words])\n","  question_corpus.append((token1 + token2))\n","tf_idf_vectoriser.fit(question_corpus)\n","idf = dict(zip(tf_idf_vectoriser.get_feature_names(), tf_idf_vectoriser.idf_))  #For Weighted W2V\n","nlp = en_core_web_lg.load()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UY0LWFd4gp9w"},"source":["def mean_tfidf_value_q1(row):\n","  q1 = word_tokenize(row['question1'].lower())\n","  stop_words = set(stopwords.words('english'))\n","  token1 = [word for word in q1 if word not in stop_words]\n","  if len(token1) > 0:\n","    q1_vector_matrix = tf_idf_vectoriser.transform(token1)  #Transform must take in a iterable so [str]\n","    return q1_vector_matrix  #Returns a sparse matrix\n","  else:\n","    return 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TvAvWQQFlHzT"},"source":["def mean_tfidf_value_q2(row):\n","  q2 = set(word_tokenize(row['question2'].lower()))\n","  stop_words = set(stopwords.words('english'))\n","  token2 = [word for word in q1 if word not in stop_words]\n","  if len(token1) > 0:\n","    q2_vector_matrix = tf_idf_vectoriser.transform(token2)  #Transform must take in a iterable so [str]\n","    return q2_vector_matrix  #Returns a sparse matrix\n","  else:\n","    return 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Tpg01HjwWHb"},"source":["def calculate_weighted_vector(question):\n","    weighted_vectors = []\n","    doc = nlp(question)\n","    mean_vec = np.zeros((len(doc[0].vector)))\n","    for word in doc:\n","        vector = word.vector\n","        if str(word) in idf:\n","            idf_weight = idf[str(word)]\n","        else:\n","            idf_weight = 0\n","        mean_vec += vector * idf_weight\n","    mean_vec /= len(doc)\n","    return mean_vec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E-q_ZSyigxlu"},"source":["def mean_idfweighted_vector_q1(row):\n","  idfweighted_vector_q1 = calculate_weighted_vector(row['question1'])\n","  return idfweighted_vector_q1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b3blVuU5lJi1"},"source":["def mean_idfweighted_vector_q2(row):\n","  idfweighted_vector_q2 = calculate_weighted_vector(row['question2'])\n","  return idfweighted_vector_q2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QdrF_cOXguKF"},"source":["train_set[\"tfidf_matrix_q1\"] = train_set.apply(mean_tfidf_value_q1, axis=1)\n","train_set[\"tfidf_matrix_q2\"] = train_set.apply(mean_tfidf_value_q2, axis=1)\n","train_set[\"mean_idfweighted_vector_q1\"] = train_set.apply(mean_idfweighted_vector_q1, axis=1)\n","train_set[\"mean_idfweighted_vector_q2\"] = train_set.apply(mean_idfweighted_vector_q2, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7wZ17e4h-UTE","colab":{"base_uri":"https://localhost:8080/","height":598},"executionInfo":{"status":"ok","timestamp":1632916864391,"user_tz":-480,"elapsed":22,"user":{"displayName":"Penn Han Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06071372039627482089"}},"outputId":"1d5a4449-bff6-4db2-82eb-b6d40ad715bc"},"source":["train_set.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id  qid1  qid2                                          question1  \\\n","0   0     1     2  what is the step by step guide to invest in sh...   \n","1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n","2   2     5     6  how can i increase the speed of my internet co...   \n","3   3     7     8  why am i mentally very lonely  how can i solve it   \n","4   4     9    10  which one dissolve in water quikly sugar  salt...   \n","\n","                                           question2  is_duplicate  \\\n","0  what is the step by step guide to invest in sh...             0   \n","1  what would happen if the indian government sto...             0   \n","2  how can internet speed be increased by hacking...             0   \n","3  find the remainder when 23  24   math  is divi...             0   \n","4             which fish would survive in salt water             0   \n","\n","   common_words_ratio  common_tokens_ratio  fuzz_partial_ratio  \\\n","0            0.478261             0.076923                 100   \n","1            0.291667             0.045977                  74   \n","2            0.166667             0.027778                  46   \n","3            0.000000             0.000000                  11   \n","4            0.200000             0.026667                  55   \n","\n","   min_longest_substring  unique_words_count  common_token_ratio_min  \\\n","0               1.000000                  11                0.089286   \n","1               0.600000                   7                0.080000   \n","2               0.172414                   4                0.034483   \n","3               0.040816                   0                0.000000   \n","4               0.157895                   4                0.052632   \n","\n","   fuzz_ratio  abs_len_difference  \\\n","0          93                   9   \n","1          66                  37   \n","2          43                  14   \n","3           9                   9   \n","4          35                  37   \n","\n","                                     tfidf_matrix_q1  \\\n","0    (0, 265917)\\t1.0\\n  (1, 265917)\\t1.0\\n  (2, ...   \n","1    (0, 267012)\\t1.0\\n  (1, 157150)\\t1.0\\n  (2, ...   \n","2    (0, 140422)\\t1.0\\n  (1, 262303)\\t1.0\\n  (2, ...   \n","3    (0, 179734)\\t1.0\\n  (1, 167642)\\t1.0\\n  (2, ...   \n","4    (0, 199549)\\t1.0\\n  (1, 84686)\\t1.0\\n  (2, 3...   \n","\n","                                     tfidf_matrix_q2  \\\n","0    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","1    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","2    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","3    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","4    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","\n","                          mean_idfweighted_vector_q1  \\\n","0  [-0.28463623353413176, 0.9678521794932229, 0.2...   \n","1  [0.7488621671994528, 0.7630542020003, 1.556344...   \n","2  [0.07783552578517369, 0.9335091284343174, -0.1...   \n","3  [-0.0391580859820048, 0.38401350875695545, -0....   \n","4  [-0.7563397467136384, 1.2002705613772073, -0.3...   \n","\n","                          mean_idfweighted_vector_q2  \n","0  [-0.017922272284825642, 0.9931385070085526, 0....  \n","1  [0.19233562227557688, 0.420634108431199, 1.343...  \n","2  [-1.574381485581398, 1.3970335014164448, -0.48...  \n","3  [-0.024673760930697123, 1.936501924196879, 1.7...  \n","4  [-0.8987145317452294, 0.07580995985439845, 0.1...  "],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","      <th>common_words_ratio</th>\n","      <th>common_tokens_ratio</th>\n","      <th>fuzz_partial_ratio</th>\n","      <th>min_longest_substring</th>\n","      <th>unique_words_count</th>\n","      <th>common_token_ratio_min</th>\n","      <th>fuzz_ratio</th>\n","      <th>abs_len_difference</th>\n","      <th>tfidf_matrix_q1</th>\n","      <th>tfidf_matrix_q2</th>\n","      <th>mean_idfweighted_vector_q1</th>\n","      <th>mean_idfweighted_vector_q2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","      <td>0.478261</td>\n","      <td>0.076923</td>\n","      <td>100</td>\n","      <td>1.000000</td>\n","      <td>11</td>\n","      <td>0.089286</td>\n","      <td>93</td>\n","      <td>9</td>\n","      <td>(0, 265917)\\t1.0\\n  (1, 265917)\\t1.0\\n  (2, ...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[-0.28463623353413176, 0.9678521794932229, 0.2...</td>\n","      <td>[-0.017922272284825642, 0.9931385070085526, 0....</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>what is the story of kohinoor  koh i noor  dia...</td>\n","      <td>what would happen if the indian government sto...</td>\n","      <td>0</td>\n","      <td>0.291667</td>\n","      <td>0.045977</td>\n","      <td>74</td>\n","      <td>0.600000</td>\n","      <td>7</td>\n","      <td>0.080000</td>\n","      <td>66</td>\n","      <td>37</td>\n","      <td>(0, 267012)\\t1.0\\n  (1, 157150)\\t1.0\\n  (2, ...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[0.7488621671994528, 0.7630542020003, 1.556344...</td>\n","      <td>[0.19233562227557688, 0.420634108431199, 1.343...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>how can i increase the speed of my internet co...</td>\n","      <td>how can internet speed be increased by hacking...</td>\n","      <td>0</td>\n","      <td>0.166667</td>\n","      <td>0.027778</td>\n","      <td>46</td>\n","      <td>0.172414</td>\n","      <td>4</td>\n","      <td>0.034483</td>\n","      <td>43</td>\n","      <td>14</td>\n","      <td>(0, 140422)\\t1.0\\n  (1, 262303)\\t1.0\\n  (2, ...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[0.07783552578517369, 0.9335091284343174, -0.1...</td>\n","      <td>[-1.574381485581398, 1.3970335014164448, -0.48...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>why am i mentally very lonely  how can i solve it</td>\n","      <td>find the remainder when 23  24   math  is divi...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11</td>\n","      <td>0.040816</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>(0, 179734)\\t1.0\\n  (1, 167642)\\t1.0\\n  (2, ...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[-0.0391580859820048, 0.38401350875695545, -0....</td>\n","      <td>[-0.024673760930697123, 1.936501924196879, 1.7...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>which one dissolve in water quikly sugar  salt...</td>\n","      <td>which fish would survive in salt water</td>\n","      <td>0</td>\n","      <td>0.200000</td>\n","      <td>0.026667</td>\n","      <td>55</td>\n","      <td>0.157895</td>\n","      <td>4</td>\n","      <td>0.052632</td>\n","      <td>35</td>\n","      <td>37</td>\n","      <td>(0, 199549)\\t1.0\\n  (1, 84686)\\t1.0\\n  (2, 3...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[-0.7563397467136384, 1.2002705613772073, -0.3...</td>\n","      <td>[-0.8987145317452294, 0.07580995985439845, 0.1...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{},"execution_count":112}]},{"cell_type":"markdown","metadata":{"id":"YCM7dbHZpXVA"},"source":["## Jeremy\n","1. common stop words min\n","2. common noun min\n","3. mean length of 2 questions"]},{"cell_type":"code","metadata":{"id":"kP_v45Qo5sz7"},"source":["stop_words = set(stopwords.words('english'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O99NJaXp6Ic6"},"source":["def get_min_len_qn(row):\n","    return min(len(row['question1'].split()), len(row['question2'].split()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a3fp8Mol6Jcu"},"source":["def calc_common_stop_words_min(row):\n","    q1 = word_tokenize(row['question1'])\n","    q2 = word_tokenize(row['question2'])\n","    stop_words_q1 = set([x for x in q1 if x in stop_words])\n","    stop_words_q2 = set([x for x in q2 if x in stop_words])\n","    num_intersect = len(stop_words_q1.intersection(stop_words_q2))\n","    return num_intersect / get_min_len_qn(row)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ttEvxQf6KiS"},"source":["train_set['common_stop_words_min'] = train_set.apply(calc_common_stop_words_min, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6_SFMAd86L3J"},"source":["def calc_common_nouns_min(row):\n","    q1_tokens = word_tokenize(row[\"question1\"].lower())\n","    q2_tokens = word_tokenize(row[\"question2\"].lower())\n","    pos_tagged_q1 = nltk.pos_tag(q1_tokens)\n","    pos_tagged_q2 = nltk.pos_tag(q2_tokens)\n","    # x[0] is the word, x[1] is the tag\n","    q1_nouns = set([x[0] for x in pos_tagged_q1 if x[1] == \"NN\"]) \n","    q2_nouns = set([x[0] for x in pos_tagged_q2 if x[1] == \"NN\"])\n","    return len(q1_nouns.intersection(q2_nouns)) / get_min_len_qn(row)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NRVzTUx66NSn"},"source":["train_set['common_nouns_min'] = train_set.apply(calc_common_nouns_min, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0Lg4pms6QT2"},"source":["def mean_len_qns(row):\n","    return (len(word_tokenize(row[\"question1\"].lower())) + len(word_tokenize(row[\"question2\"].lower()))) / 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pmGKp7y66RwP"},"source":["train_set['mean_len'] = train_set.apply(mean_len_qns, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fgp4qLPq6XqW","colab":{"base_uri":"https://localhost:8080/","height":627},"executionInfo":{"status":"ok","timestamp":1632918091512,"user_tz":-480,"elapsed":58,"user":{"displayName":"Penn Han Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06071372039627482089"}},"outputId":"6cb08f6e-1034-40d0-ea32-81d31dea18ff"},"source":["train_set.head(5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id  qid1  qid2                                          question1  \\\n","0   0     1     2  what is the step by step guide to invest in sh...   \n","1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n","2   2     5     6  how can i increase the speed of my internet co...   \n","3   3     7     8  why am i mentally very lonely  how can i solve it   \n","4   4     9    10  which one dissolve in water quikly sugar  salt...   \n","\n","                                           question2  is_duplicate  \\\n","0  what is the step by step guide to invest in sh...             0   \n","1  what would happen if the indian government sto...             0   \n","2  how can internet speed be increased by hacking...             0   \n","3  find the remainder when 23  24   math  is divi...             0   \n","4             which fish would survive in salt water             0   \n","\n","   common_words_ratio  common_tokens_ratio  fuzz_partial_ratio  \\\n","0            0.478261             0.076923                 100   \n","1            0.291667             0.045977                  74   \n","2            0.166667             0.027778                  46   \n","3            0.000000             0.000000                  11   \n","4            0.200000             0.026667                  55   \n","\n","   min_longest_substring  ...  common_token_ratio_min  fuzz_ratio  \\\n","0               1.000000  ...                0.089286          93   \n","1               0.600000  ...                0.080000          66   \n","2               0.172414  ...                0.034483          43   \n","3               0.040816  ...                0.000000           9   \n","4               0.157895  ...                0.052632          35   \n","\n","   abs_len_difference                                    tfidf_matrix_q1  \\\n","0                   9    (0, 265917)\\t1.0\\n  (1, 265917)\\t1.0\\n  (2, ...   \n","1                  37    (0, 267012)\\t1.0\\n  (1, 157150)\\t1.0\\n  (2, ...   \n","2                  14    (0, 140422)\\t1.0\\n  (1, 262303)\\t1.0\\n  (2, ...   \n","3                   9    (0, 179734)\\t1.0\\n  (1, 167642)\\t1.0\\n  (2, ...   \n","4                  37    (0, 199549)\\t1.0\\n  (1, 84686)\\t1.0\\n  (2, 3...   \n","\n","                                     tfidf_matrix_q2  \\\n","0    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","1    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","2    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","3    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","4    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","\n","                          mean_idfweighted_vector_q1  \\\n","0  [-0.28463623353413176, 0.9678521794932229, 0.2...   \n","1  [0.7488621671994528, 0.7630542020003, 1.556344...   \n","2  [0.07783552578517369, 0.9335091284343174, -0.1...   \n","3  [-0.0391580859820048, 0.38401350875695545, -0....   \n","4  [-0.7563397467136384, 1.2002705613772073, -0.3...   \n","\n","                          mean_idfweighted_vector_q2 common_stop_words_min  \\\n","0  [-0.017922272284825642, 0.9931385070085526, 0....              0.500000   \n","1  [0.19233562227557688, 0.420634108431199, 1.343...              0.300000   \n","2  [-1.574381485581398, 1.3970335014164448, -0.48...              0.200000   \n","3  [-0.024673760930697123, 1.936501924196879, 1.7...              0.000000   \n","4  [-0.8987145317452294, 0.07580995985439845, 0.1...              0.285714   \n","\n","   common_nouns_min  mean_len  \n","0          0.250000      13.0  \n","1          0.300000      12.5  \n","2          0.100000      12.0  \n","3          0.000000      11.5  \n","4          0.285714      10.0  \n","\n","[5 rows x 21 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","      <th>common_words_ratio</th>\n","      <th>common_tokens_ratio</th>\n","      <th>fuzz_partial_ratio</th>\n","      <th>min_longest_substring</th>\n","      <th>...</th>\n","      <th>common_token_ratio_min</th>\n","      <th>fuzz_ratio</th>\n","      <th>abs_len_difference</th>\n","      <th>tfidf_matrix_q1</th>\n","      <th>tfidf_matrix_q2</th>\n","      <th>mean_idfweighted_vector_q1</th>\n","      <th>mean_idfweighted_vector_q2</th>\n","      <th>common_stop_words_min</th>\n","      <th>common_nouns_min</th>\n","      <th>mean_len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","      <td>0.478261</td>\n","      <td>0.076923</td>\n","      <td>100</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>0.089286</td>\n","      <td>93</td>\n","      <td>9</td>\n","      <td>(0, 265917)\\t1.0\\n  (1, 265917)\\t1.0\\n  (2, ...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[-0.28463623353413176, 0.9678521794932229, 0.2...</td>\n","      <td>[-0.017922272284825642, 0.9931385070085526, 0....</td>\n","      <td>0.500000</td>\n","      <td>0.250000</td>\n","      <td>13.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>what is the story of kohinoor  koh i noor  dia...</td>\n","      <td>what would happen if the indian government sto...</td>\n","      <td>0</td>\n","      <td>0.291667</td>\n","      <td>0.045977</td>\n","      <td>74</td>\n","      <td>0.600000</td>\n","      <td>...</td>\n","      <td>0.080000</td>\n","      <td>66</td>\n","      <td>37</td>\n","      <td>(0, 267012)\\t1.0\\n  (1, 157150)\\t1.0\\n  (2, ...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[0.7488621671994528, 0.7630542020003, 1.556344...</td>\n","      <td>[0.19233562227557688, 0.420634108431199, 1.343...</td>\n","      <td>0.300000</td>\n","      <td>0.300000</td>\n","      <td>12.5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>how can i increase the speed of my internet co...</td>\n","      <td>how can internet speed be increased by hacking...</td>\n","      <td>0</td>\n","      <td>0.166667</td>\n","      <td>0.027778</td>\n","      <td>46</td>\n","      <td>0.172414</td>\n","      <td>...</td>\n","      <td>0.034483</td>\n","      <td>43</td>\n","      <td>14</td>\n","      <td>(0, 140422)\\t1.0\\n  (1, 262303)\\t1.0\\n  (2, ...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[0.07783552578517369, 0.9335091284343174, -0.1...</td>\n","      <td>[-1.574381485581398, 1.3970335014164448, -0.48...</td>\n","      <td>0.200000</td>\n","      <td>0.100000</td>\n","      <td>12.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>why am i mentally very lonely  how can i solve it</td>\n","      <td>find the remainder when 23  24   math  is divi...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11</td>\n","      <td>0.040816</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>9</td>\n","      <td>9</td>\n","      <td>(0, 179734)\\t1.0\\n  (1, 167642)\\t1.0\\n  (2, ...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[-0.0391580859820048, 0.38401350875695545, -0....</td>\n","      <td>[-0.024673760930697123, 1.936501924196879, 1.7...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11.5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>which one dissolve in water quikly sugar  salt...</td>\n","      <td>which fish would survive in salt water</td>\n","      <td>0</td>\n","      <td>0.200000</td>\n","      <td>0.026667</td>\n","      <td>55</td>\n","      <td>0.157895</td>\n","      <td>...</td>\n","      <td>0.052632</td>\n","      <td>35</td>\n","      <td>37</td>\n","      <td>(0, 199549)\\t1.0\\n  (1, 84686)\\t1.0\\n  (2, 3...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[-0.7563397467136384, 1.2002705613772073, -0.3...</td>\n","      <td>[-0.8987145317452294, 0.07580995985439845, 0.1...</td>\n","      <td>0.285714</td>\n","      <td>0.285714</td>\n","      <td>10.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>"]},"metadata":{},"execution_count":121}]},{"cell_type":"markdown","metadata":{"id":"hE50X--UjtRR"},"source":["##Kay Chi\n","1. Common stop words max\n","2. Common noun max\n","3. Ratio of length of questions"]},{"cell_type":"code","metadata":{"id":"r_D34iHTtILS"},"source":["def get_max_len_qn(row):\n","    return max(len(row['question1'].split()), len(row['question2'].split()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bou-DlcWtIC_"},"source":["def calc_common_stop_words_max(row):\n","    q1 = word_tokenize(row['question1'])\n","    q2 = word_tokenize(row['question2'])\n","    stop_words_q1 = set([x for x in q1 if x in stop_words])\n","    stop_words_q2 = set([x for x in q2 if x in stop_words])\n","    num_intersect = len(stop_words_q1.intersection(stop_words_q2))\n","    return num_intersect / get_max_len_qn(row)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_p0n0iDUubXK"},"source":["train_set['common_stop_words_max'] = train_set.apply(calc_common_stop_words_max, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8skmwJPawOix"},"source":["def calc_common_nouns_max(row):\n","    q1_tokens = word_tokenize(row[\"question1\"].lower())\n","    q2_tokens = word_tokenize(row[\"question2\"].lower())\n","    pos_tagged_q1 = nltk.pos_tag(q1_tokens)\n","    pos_tagged_q2 = nltk.pos_tag(q2_tokens)\n","    # x[0] is the word, x[1] is the tag\n","    q1_nouns = set([x[0] for x in pos_tagged_q1 if x[1] == \"NN\"]) \n","    q2_nouns = set([x[0] for x in pos_tagged_q2 if x[1] == \"NN\"])\n","    return len(q1_nouns.intersection(q2_nouns)) / get_max_len_qn(row)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZOAgVZzb0_fw"},"source":["train_set['common_nouns_max'] = train_set.apply(calc_common_nouns_max, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"58E1CpXM4SXM"},"source":["def ratio_len_qn(row):\n","  q1 = row['question1']\n","  q2 = row['question2']\n","  return len(q1) / len(q2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_8WkMoK64hlc"},"source":["train_set['ratio_len_qn'] = train_set.apply(ratio_len_qn, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bmDkg6Tjwe9","colab":{"base_uri":"https://localhost:8080/","height":627},"executionInfo":{"status":"ok","timestamp":1632919273909,"user_tz":-480,"elapsed":89,"user":{"displayName":"Penn Han Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06071372039627482089"}},"outputId":"70f4a9d3-d50a-42e6-ae66-9c91c3277eb0"},"source":["train_set.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id  qid1  qid2                                          question1  \\\n","0   0     1     2  what is the step by step guide to invest in sh...   \n","1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n","2   2     5     6  how can i increase the speed of my internet co...   \n","3   3     7     8  why am i mentally very lonely  how can i solve it   \n","4   4     9    10  which one dissolve in water quikly sugar  salt...   \n","\n","                                           question2  is_duplicate  \\\n","0  what is the step by step guide to invest in sh...             0   \n","1  what would happen if the indian government sto...             0   \n","2  how can internet speed be increased by hacking...             0   \n","3  find the remainder when 23  24   math  is divi...             0   \n","4             which fish would survive in salt water             0   \n","\n","   common_words_ratio  common_tokens_ratio  fuzz_partial_ratio  \\\n","0            0.478261             0.076923                 100   \n","1            0.291667             0.045977                  74   \n","2            0.166667             0.027778                  46   \n","3            0.000000             0.000000                  11   \n","4            0.200000             0.026667                  55   \n","\n","   min_longest_substring  ...  \\\n","0               1.000000  ...   \n","1               0.600000  ...   \n","2               0.172414  ...   \n","3               0.040816  ...   \n","4               0.157895  ...   \n","\n","                                     tfidf_matrix_q1  \\\n","0    (0, 265917)\\t1.0\\n  (1, 265917)\\t1.0\\n  (2, ...   \n","1    (0, 267012)\\t1.0\\n  (1, 157150)\\t1.0\\n  (2, ...   \n","2    (0, 140422)\\t1.0\\n  (1, 262303)\\t1.0\\n  (2, ...   \n","3    (0, 179734)\\t1.0\\n  (1, 167642)\\t1.0\\n  (2, ...   \n","4    (0, 199549)\\t1.0\\n  (1, 84686)\\t1.0\\n  (2, 3...   \n","\n","                                     tfidf_matrix_q2  \\\n","0    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","1    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","2    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","3    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","4    (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...   \n","\n","                          mean_idfweighted_vector_q1  \\\n","0  [-0.28463623353413176, 0.9678521794932229, 0.2...   \n","1  [0.7488621671994528, 0.7630542020003, 1.556344...   \n","2  [0.07783552578517369, 0.9335091284343174, -0.1...   \n","3  [-0.0391580859820048, 0.38401350875695545, -0....   \n","4  [-0.7563397467136384, 1.2002705613772073, -0.3...   \n","\n","                          mean_idfweighted_vector_q2 common_stop_words_min  \\\n","0  [-0.017922272284825642, 0.9931385070085526, 0....              0.500000   \n","1  [0.19233562227557688, 0.420634108431199, 1.343...              0.300000   \n","2  [-1.574381485581398, 1.3970335014164448, -0.48...              0.200000   \n","3  [-0.024673760930697123, 1.936501924196879, 1.7...              0.000000   \n","4  [-0.8987145317452294, 0.07580995985439845, 0.1...              0.285714   \n","\n","  common_nouns_min mean_len common_stop_words_max  common_nouns_max  \\\n","0         0.250000     13.0              0.428571          0.214286   \n","1         0.300000     12.5              0.200000          0.200000   \n","2         0.100000     12.0              0.142857          0.071429   \n","3         0.000000     11.5              0.000000          0.000000   \n","4         0.285714     10.0              0.153846          0.153846   \n","\n","   ratio_len_qn  \n","0      1.160714  \n","1      0.574713  \n","2      1.241379  \n","3      0.844828  \n","4      1.973684  \n","\n","[5 rows x 24 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","      <th>common_words_ratio</th>\n","      <th>common_tokens_ratio</th>\n","      <th>fuzz_partial_ratio</th>\n","      <th>min_longest_substring</th>\n","      <th>...</th>\n","      <th>tfidf_matrix_q1</th>\n","      <th>tfidf_matrix_q2</th>\n","      <th>mean_idfweighted_vector_q1</th>\n","      <th>mean_idfweighted_vector_q2</th>\n","      <th>common_stop_words_min</th>\n","      <th>common_nouns_min</th>\n","      <th>mean_len</th>\n","      <th>common_stop_words_max</th>\n","      <th>common_nouns_max</th>\n","      <th>ratio_len_qn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","      <td>0.478261</td>\n","      <td>0.076923</td>\n","      <td>100</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>(0, 265917)\\t1.0\\n  (1, 265917)\\t1.0\\n  (2, ...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[-0.28463623353413176, 0.9678521794932229, 0.2...</td>\n","      <td>[-0.017922272284825642, 0.9931385070085526, 0....</td>\n","      <td>0.500000</td>\n","      <td>0.250000</td>\n","      <td>13.0</td>\n","      <td>0.428571</td>\n","      <td>0.214286</td>\n","      <td>1.160714</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>what is the story of kohinoor  koh i noor  dia...</td>\n","      <td>what would happen if the indian government sto...</td>\n","      <td>0</td>\n","      <td>0.291667</td>\n","      <td>0.045977</td>\n","      <td>74</td>\n","      <td>0.600000</td>\n","      <td>...</td>\n","      <td>(0, 267012)\\t1.0\\n  (1, 157150)\\t1.0\\n  (2, ...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[0.7488621671994528, 0.7630542020003, 1.556344...</td>\n","      <td>[0.19233562227557688, 0.420634108431199, 1.343...</td>\n","      <td>0.300000</td>\n","      <td>0.300000</td>\n","      <td>12.5</td>\n","      <td>0.200000</td>\n","      <td>0.200000</td>\n","      <td>0.574713</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>how can i increase the speed of my internet co...</td>\n","      <td>how can internet speed be increased by hacking...</td>\n","      <td>0</td>\n","      <td>0.166667</td>\n","      <td>0.027778</td>\n","      <td>46</td>\n","      <td>0.172414</td>\n","      <td>...</td>\n","      <td>(0, 140422)\\t1.0\\n  (1, 262303)\\t1.0\\n  (2, ...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[0.07783552578517369, 0.9335091284343174, -0.1...</td>\n","      <td>[-1.574381485581398, 1.3970335014164448, -0.48...</td>\n","      <td>0.200000</td>\n","      <td>0.100000</td>\n","      <td>12.0</td>\n","      <td>0.142857</td>\n","      <td>0.071429</td>\n","      <td>1.241379</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>why am i mentally very lonely  how can i solve it</td>\n","      <td>find the remainder when 23  24   math  is divi...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11</td>\n","      <td>0.040816</td>\n","      <td>...</td>\n","      <td>(0, 179734)\\t1.0\\n  (1, 167642)\\t1.0\\n  (2, ...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[-0.0391580859820048, 0.38401350875695545, -0....</td>\n","      <td>[-0.024673760930697123, 1.936501924196879, 1.7...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11.5</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.844828</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>which one dissolve in water quikly sugar  salt...</td>\n","      <td>which fish would survive in salt water</td>\n","      <td>0</td>\n","      <td>0.200000</td>\n","      <td>0.026667</td>\n","      <td>55</td>\n","      <td>0.157895</td>\n","      <td>...</td>\n","      <td>(0, 199549)\\t1.0\\n  (1, 84686)\\t1.0\\n  (2, 3...</td>\n","      <td>(0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...</td>\n","      <td>[-0.7563397467136384, 1.2002705613772073, -0.3...</td>\n","      <td>[-0.8987145317452294, 0.07580995985439845, 0.1...</td>\n","      <td>0.285714</td>\n","      <td>0.285714</td>\n","      <td>10.0</td>\n","      <td>0.153846</td>\n","      <td>0.153846</td>\n","      <td>1.973684</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 24 columns</p>\n","</div>"]},"metadata":{},"execution_count":129}]},{"cell_type":"markdown","metadata":{"id":"wy4iRdRk1toC"},"source":["## YS\n","1. Common Word Ratio max ( words common/ max(len(q1), len(q2))) \n","2. Common Adjectives max ( common adjectives /max(len(q1), len(q2)))\n","3. Fuzz Token Set Ratio "]},{"cell_type":"code","metadata":{"id":"chI-Q-MP2Ljt"},"source":["def common_word_ratio_max(row):\n","  q1 = row['question1']\n","  q2 = row['question2']\n","  return len(set(q1).intersection(set(q2))) / max(len(q1), len(q2))\n","\n","train_set['common_word_ratio_max'] = train_set.apply(common_word_ratio_max, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6waA2IaX3GkL"},"source":["# This has been tested to be correct, but result seems off.\n","def get_adjectives(text):\n","  blob = TextBlob(text)\n","  return set(word for (word,tag) in blob.tags if tag.startswith(\"JJ\"))\n","  \n","def common_adjectives_max(row):\n","  q1 = row['question1']\n","  q2 = row['question2']\n","  return len(get_adjectives(q1).intersection(get_adjectives(q2))) / max(len(q1), len(q2))\n","\n","train_set['common_adjectives_max'] = train_set.apply(common_adjectives_max, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dn4sZUH8Awt"},"source":["def calc_fuzz_token_set_ratio(row):\n","  q1 = row['question1']\n","  q2 = row['question2']\n","  return fuzz.token_set_ratio(q1, q2)\n","\n","train_set['fuzz_token_set_ratio'] = train_set.apply(calc_fuzz_token_set_ratio, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lPSKUsk--1RX","colab":{"base_uri":"https://localhost:8080/","height":627},"executionInfo":{"status":"ok","timestamp":1632920550372,"user_tz":-480,"elapsed":34,"user":{"displayName":"Penn Han Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06071372039627482089"}},"outputId":"bc09591a-ac0a-4839-c52d-dbe5e5c98bb5"},"source":["train_set.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id  qid1  qid2                                          question1  \\\n","0   0     1     2  what is the step by step guide to invest in sh...   \n","1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n","2   2     5     6  how can i increase the speed of my internet co...   \n","3   3     7     8  why am i mentally very lonely  how can i solve it   \n","4   4     9    10  which one dissolve in water quikly sugar  salt...   \n","\n","                                           question2  is_duplicate  \\\n","0  what is the step by step guide to invest in sh...             0   \n","1  what would happen if the indian government sto...             0   \n","2  how can internet speed be increased by hacking...             0   \n","3  find the remainder when 23  24   math  is divi...             0   \n","4             which fish would survive in salt water             0   \n","\n","   common_words_ratio  common_tokens_ratio  fuzz_partial_ratio  \\\n","0            0.478261             0.076923                 100   \n","1            0.291667             0.045977                  74   \n","2            0.166667             0.027778                  46   \n","3            0.000000             0.000000                  11   \n","4            0.200000             0.026667                  55   \n","\n","   min_longest_substring  ...  \\\n","0               1.000000  ...   \n","1               0.600000  ...   \n","2               0.172414  ...   \n","3               0.040816  ...   \n","4               0.157895  ...   \n","\n","                          mean_idfweighted_vector_q2  common_stop_words_min  \\\n","0  [-0.017922272284825642, 0.9931385070085526, 0....               0.500000   \n","1  [0.19233562227557688, 0.420634108431199, 1.343...               0.300000   \n","2  [-1.574381485581398, 1.3970335014164448, -0.48...               0.200000   \n","3  [-0.024673760930697123, 1.936501924196879, 1.7...               0.000000   \n","4  [-0.8987145317452294, 0.07580995985439845, 0.1...               0.285714   \n","\n","   common_nouns_min  mean_len common_stop_words_max common_nouns_max  \\\n","0          0.250000      13.0              0.428571         0.214286   \n","1          0.300000      12.5              0.200000         0.200000   \n","2          0.100000      12.0              0.142857         0.071429   \n","3          0.000000      11.5              0.000000         0.000000   \n","4          0.285714      10.0              0.153846         0.153846   \n","\n","  ratio_len_qn common_word_ratio_max  common_adjectives_max  \\\n","0     1.160714              0.307692                    0.0   \n","1     0.574713              0.172414                    0.0   \n","2     1.241379              0.236111                    0.0   \n","3     0.844828              0.224138                    0.0   \n","4     1.973684              0.213333                    0.0   \n","\n","   fuzz_token_set_ratio  \n","0                   100  \n","1                    86  \n","2                    63  \n","3                    28  \n","4                    67  \n","\n","[5 rows x 27 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","      <th>common_words_ratio</th>\n","      <th>common_tokens_ratio</th>\n","      <th>fuzz_partial_ratio</th>\n","      <th>min_longest_substring</th>\n","      <th>...</th>\n","      <th>mean_idfweighted_vector_q2</th>\n","      <th>common_stop_words_min</th>\n","      <th>common_nouns_min</th>\n","      <th>mean_len</th>\n","      <th>common_stop_words_max</th>\n","      <th>common_nouns_max</th>\n","      <th>ratio_len_qn</th>\n","      <th>common_word_ratio_max</th>\n","      <th>common_adjectives_max</th>\n","      <th>fuzz_token_set_ratio</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","      <td>0.478261</td>\n","      <td>0.076923</td>\n","      <td>100</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>[-0.017922272284825642, 0.9931385070085526, 0....</td>\n","      <td>0.500000</td>\n","      <td>0.250000</td>\n","      <td>13.0</td>\n","      <td>0.428571</td>\n","      <td>0.214286</td>\n","      <td>1.160714</td>\n","      <td>0.307692</td>\n","      <td>0.0</td>\n","      <td>100</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>what is the story of kohinoor  koh i noor  dia...</td>\n","      <td>what would happen if the indian government sto...</td>\n","      <td>0</td>\n","      <td>0.291667</td>\n","      <td>0.045977</td>\n","      <td>74</td>\n","      <td>0.600000</td>\n","      <td>...</td>\n","      <td>[0.19233562227557688, 0.420634108431199, 1.343...</td>\n","      <td>0.300000</td>\n","      <td>0.300000</td>\n","      <td>12.5</td>\n","      <td>0.200000</td>\n","      <td>0.200000</td>\n","      <td>0.574713</td>\n","      <td>0.172414</td>\n","      <td>0.0</td>\n","      <td>86</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>how can i increase the speed of my internet co...</td>\n","      <td>how can internet speed be increased by hacking...</td>\n","      <td>0</td>\n","      <td>0.166667</td>\n","      <td>0.027778</td>\n","      <td>46</td>\n","      <td>0.172414</td>\n","      <td>...</td>\n","      <td>[-1.574381485581398, 1.3970335014164448, -0.48...</td>\n","      <td>0.200000</td>\n","      <td>0.100000</td>\n","      <td>12.0</td>\n","      <td>0.142857</td>\n","      <td>0.071429</td>\n","      <td>1.241379</td>\n","      <td>0.236111</td>\n","      <td>0.0</td>\n","      <td>63</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>why am i mentally very lonely  how can i solve it</td>\n","      <td>find the remainder when 23  24   math  is divi...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11</td>\n","      <td>0.040816</td>\n","      <td>...</td>\n","      <td>[-0.024673760930697123, 1.936501924196879, 1.7...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11.5</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.844828</td>\n","      <td>0.224138</td>\n","      <td>0.0</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>which one dissolve in water quikly sugar  salt...</td>\n","      <td>which fish would survive in salt water</td>\n","      <td>0</td>\n","      <td>0.200000</td>\n","      <td>0.026667</td>\n","      <td>55</td>\n","      <td>0.157895</td>\n","      <td>...</td>\n","      <td>[-0.8987145317452294, 0.07580995985439845, 0.1...</td>\n","      <td>0.285714</td>\n","      <td>0.285714</td>\n","      <td>10.0</td>\n","      <td>0.153846</td>\n","      <td>0.153846</td>\n","      <td>1.973684</td>\n","      <td>0.213333</td>\n","      <td>0.0</td>\n","      <td>67</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 27 columns</p>\n","</div>"]},"metadata":{},"execution_count":133}]},{"cell_type":"markdown","metadata":{"id":"hgxQeK8TqH8m"},"source":["##**Neaton**"]},{"cell_type":"code","metadata":{"id":"914YiTxLPiyl"},"source":["def common_words_ratio_min(row):\n","  set1 = set(row['question1'].lower().split())\n","  set2 = set(row['question2'].lower().split())\n","  common_words = len(set1.intersection(set2))\n","  return common_words/min(len(set1), len(set2))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4MCNlf0rISD"},"source":["train_set['common_words_ratio_min'] = train_set.apply(common_words_ratio_min, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P4kBabFxrbRn"},"source":["# This has been tested to be correct, but result seems off.\n","def get_adjectives(text):\n","  blob = TextBlob(text)\n","  return set(word for (word,tag) in blob.tags if tag.startswith(\"JJ\"))\n","  \n","def common_adjectives_min(row):\n","  q1 = row['question1']\n","  q2 = row['question2']\n","  return len(get_adjectives(q1).intersection(get_adjectives(q2))) / min(len(q1), len(q2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HB6ymClrsFdU"},"source":["train_set['common_adjectives_min'] = train_set.apply(common_adjectives_min, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3JJWQIwVr3Kr"},"source":["def fuzz_token_sort_ratio(row):\n","  q1 = row['question1']\n","  q2 = row['question2']\n","  fuzz_token = fuzz.token_sort_ratio(q1,q2)\n","  return fuzz_token"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlJSX45csHGa"},"source":["train_set['fuzz_token_sort_ratio'] = train_set.apply(fuzz_token_sort_ratio, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Qb_zvHSsL0r"},"source":["def max_longest_substring(row):\n","  q1 = row['question1']\n","  q2 = row['question2']\n","  match = SequenceMatcher(None, q1, q2).find_longest_match(0, len(q1), 0, len(q2))\n","  return match.size/max(len(q1), len(q2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NfAa_tvosR6u"},"source":["train_set['max_longest_substring'] = train_set.apply(max_longest_substring, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2oURlv5HsX0Y","colab":{"base_uri":"https://localhost:8080/","height":627},"executionInfo":{"status":"ok","timestamp":1632921864039,"user_tz":-480,"elapsed":27,"user":{"displayName":"Penn Han Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06071372039627482089"}},"outputId":"94cbbea1-99a3-4897-9dab-c86a2e6f11e8"},"source":["train_set.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id  qid1  qid2                                          question1  \\\n","0   0     1     2  what is the step by step guide to invest in sh...   \n","1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n","2   2     5     6  how can i increase the speed of my internet co...   \n","3   3     7     8  why am i mentally very lonely  how can i solve it   \n","4   4     9    10  which one dissolve in water quikly sugar  salt...   \n","\n","                                           question2  is_duplicate  \\\n","0  what is the step by step guide to invest in sh...             0   \n","1  what would happen if the indian government sto...             0   \n","2  how can internet speed be increased by hacking...             0   \n","3  find the remainder when 23  24   math  is divi...             0   \n","4             which fish would survive in salt water             0   \n","\n","   common_words_ratio  common_tokens_ratio  fuzz_partial_ratio  \\\n","0            0.478261             0.076923                 100   \n","1            0.291667             0.045977                  74   \n","2            0.166667             0.027778                  46   \n","3            0.000000             0.000000                  11   \n","4            0.200000             0.026667                  55   \n","\n","   min_longest_substring  ...  common_stop_words_max  common_nouns_max  \\\n","0               1.000000  ...               0.428571          0.214286   \n","1               0.600000  ...               0.200000          0.200000   \n","2               0.172414  ...               0.142857          0.071429   \n","3               0.040816  ...               0.000000          0.000000   \n","4               0.157895  ...               0.153846          0.153846   \n","\n","   ratio_len_qn  common_word_ratio_max common_adjectives_max  \\\n","0      1.160714               0.307692                   0.0   \n","1      0.574713               0.172414                   0.0   \n","2      1.241379               0.236111                   0.0   \n","3      0.844828               0.224138                   0.0   \n","4      1.973684               0.213333                   0.0   \n","\n","  fuzz_token_set_ratio common_words_ratio_min common_adjectives_min  \\\n","0                  100               1.000000                   0.0   \n","1                   86               0.700000                   0.0   \n","2                   63               0.400000                   0.0   \n","3                   28               0.000000                   0.0   \n","4                   67               0.571429                   0.0   \n","\n","   fuzz_token_sort_ratio  max_longest_substring  \n","0                     93               0.861538  \n","1                     63               0.344828  \n","2                     63               0.138889  \n","3                     25               0.034483  \n","4                     47               0.080000  \n","\n","[5 rows x 31 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","      <th>common_words_ratio</th>\n","      <th>common_tokens_ratio</th>\n","      <th>fuzz_partial_ratio</th>\n","      <th>min_longest_substring</th>\n","      <th>...</th>\n","      <th>common_stop_words_max</th>\n","      <th>common_nouns_max</th>\n","      <th>ratio_len_qn</th>\n","      <th>common_word_ratio_max</th>\n","      <th>common_adjectives_max</th>\n","      <th>fuzz_token_set_ratio</th>\n","      <th>common_words_ratio_min</th>\n","      <th>common_adjectives_min</th>\n","      <th>fuzz_token_sort_ratio</th>\n","      <th>max_longest_substring</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>what is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","      <td>0.478261</td>\n","      <td>0.076923</td>\n","      <td>100</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>0.428571</td>\n","      <td>0.214286</td>\n","      <td>1.160714</td>\n","      <td>0.307692</td>\n","      <td>0.0</td>\n","      <td>100</td>\n","      <td>1.000000</td>\n","      <td>0.0</td>\n","      <td>93</td>\n","      <td>0.861538</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>what is the story of kohinoor  koh i noor  dia...</td>\n","      <td>what would happen if the indian government sto...</td>\n","      <td>0</td>\n","      <td>0.291667</td>\n","      <td>0.045977</td>\n","      <td>74</td>\n","      <td>0.600000</td>\n","      <td>...</td>\n","      <td>0.200000</td>\n","      <td>0.200000</td>\n","      <td>0.574713</td>\n","      <td>0.172414</td>\n","      <td>0.0</td>\n","      <td>86</td>\n","      <td>0.700000</td>\n","      <td>0.0</td>\n","      <td>63</td>\n","      <td>0.344828</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>how can i increase the speed of my internet co...</td>\n","      <td>how can internet speed be increased by hacking...</td>\n","      <td>0</td>\n","      <td>0.166667</td>\n","      <td>0.027778</td>\n","      <td>46</td>\n","      <td>0.172414</td>\n","      <td>...</td>\n","      <td>0.142857</td>\n","      <td>0.071429</td>\n","      <td>1.241379</td>\n","      <td>0.236111</td>\n","      <td>0.0</td>\n","      <td>63</td>\n","      <td>0.400000</td>\n","      <td>0.0</td>\n","      <td>63</td>\n","      <td>0.138889</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>why am i mentally very lonely  how can i solve it</td>\n","      <td>find the remainder when 23  24   math  is divi...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>11</td>\n","      <td>0.040816</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.844828</td>\n","      <td>0.224138</td>\n","      <td>0.0</td>\n","      <td>28</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>25</td>\n","      <td>0.034483</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>which one dissolve in water quikly sugar  salt...</td>\n","      <td>which fish would survive in salt water</td>\n","      <td>0</td>\n","      <td>0.200000</td>\n","      <td>0.026667</td>\n","      <td>55</td>\n","      <td>0.157895</td>\n","      <td>...</td>\n","      <td>0.153846</td>\n","      <td>0.153846</td>\n","      <td>1.973684</td>\n","      <td>0.213333</td>\n","      <td>0.0</td>\n","      <td>67</td>\n","      <td>0.571429</td>\n","      <td>0.0</td>\n","      <td>47</td>\n","      <td>0.080000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 31 columns</p>\n","</div>"]},"metadata":{},"execution_count":142}]},{"cell_type":"code","metadata":{"id":"EpQHUOGgPfTF"},"source":["train_set.to_csv('train_set_with_features.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o7CRxJBy-4ku","executionInfo":{"status":"ok","timestamp":1632926234739,"user_tz":-480,"elapsed":29,"user":{"displayName":"Penn Han Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06071372039627482089"}},"outputId":"d76430a8-c51a-4ff4-80f3-124f3e913907"},"source":["train_set[\"tfidf_matrix_q1\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0           (0, 265917)\\t1.0\\n  (1, 265917)\\t1.0\\n  (2, ...\n","1           (0, 267012)\\t1.0\\n  (1, 157150)\\t1.0\\n  (2, ...\n","2           (0, 140422)\\t1.0\\n  (1, 262303)\\t1.0\\n  (2, ...\n","3           (0, 179734)\\t1.0\\n  (1, 167642)\\t1.0\\n  (2, ...\n","4           (0, 199549)\\t1.0\\n  (1, 84686)\\t1.0\\n  (2, 3...\n","                                ...                        \n","404285      (0, 173304)\\t1.0\\n  (1, 155186)\\t1.0\\n  (2, ...\n","404286      (0, 34288)\\t1.0\\n  (1, 162979)\\t1.0\\n  (2, 7...\n","404287                  (0, 199549)\\t1.0\\n  (1, 59341)\\t1.0\n","404288      (0, 23149)\\t1.0\\n  (1, 20462)\\t1.0\\n  (2, 67...\n","404289      (0, 164246)\\t1.0\\n  (1, 251513)\\t1.0\\n  (2, ...\n","Name: tfidf_matrix_q1, Length: 404266, dtype: object"]},"metadata":{},"execution_count":147}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ay45uFm6_cmo","executionInfo":{"status":"ok","timestamp":1632926292979,"user_tz":-480,"elapsed":44,"user":{"displayName":"Penn Han Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06071372039627482089"}},"outputId":"fca7adff-613e-40c3-d7f2-cacce20c98b8"},"source":["train_set[\"mean_idfweighted_vector_q1\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0         [-0.28463623353413176, 0.9678521794932229, 0.2...\n","1         [0.7488621671994528, 0.7630542020003, 1.556344...\n","2         [0.07783552578517369, 0.9335091284343174, -0.1...\n","3         [-0.0391580859820048, 0.38401350875695545, -0....\n","4         [-0.7563397467136384, 1.2002705613772073, -0.3...\n","                                ...                        \n","404285    [-0.3489754008395331, -0.16148637341601507, 0....\n","404286    [-0.38235482573509216, 0.9946302771568298, -0....\n","404287    [-0.008712098002433777, -0.23649294674396515, ...\n","404288    [-0.021404032905896504, 0.6523470787538422, 0....\n","404289    [-0.586537778377533, -0.2981147915124893, -0.9...\n","Name: mean_idfweighted_vector_q1, Length: 404266, dtype: object"]},"metadata":{},"execution_count":148}]},{"cell_type":"code","metadata":{"id":"5_QrGP4lARXB"},"source":["train_set2 = train_set.drop(columns=[\"tfidf_matrix_q1\", \"tfidf_matrix_q2\", \"mean_idfweighted_vector_q1\", \"mean_idfweighted_vector_q2\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UO-3ZRAqAvTk"},"source":["train_set2.to_csv(\"train_set_2.csv\")"],"execution_count":null,"outputs":[]}]}